方案要点：
		1）Text CNN（缺点：语义泛化能力不强，比如“音量有点低了”）
		2）Python：离线训练+导出模型；Go：生产推理服务（CPU）
		3）支持多语言（中文、英文、日语）
		4）一级意图数量规模：现在10个，预计 1–2 年内到50个。
	目标：
		1）一份 PyTorch Text CNN → ONNX 的完整训练脚本
		2）一份 Go + onnxruntime 的最小可跑推理服务
		3）压测方案（验证 CPU vs GPU 的实际差距）当前还不需要

下面给你一套可直接落地、工程完整、与你方案严格对齐的实现说明与代码示例。内容分三部分，对应你的目标 1）2）（第 3 点压测方案暂不展开）。

说明：
* Text CNN：多语言（中 / 英 / 日）统一模型
* Python：仅离线训练 + 导出 ONNX
* Go：CPU 推理服务（onnxruntime）
* 显式支持 OOS / 拒识
* 设计上可从 10 个一级意图平滑扩展到 50 个

一、PyTorch：Text CNN 训练 → ONNX 导出（完整示例）
1. 模型定义（Text CNN）
```Python 
# model.py
import torch
import torch.nn as nn
import torch.nn.functional as F

class TextCNN(nn.Module):
    def __init__(
        self,
        vocab_size: int,
        embed_dim: int,
        num_classes: int,
        kernel_sizes=(2, 3, 4),
        num_filters=64,
        dropout=0.3,
        padding_idx=0,
    ):
        super().__init__()

        self.embedding = nn.Embedding(
            vocab_size, embed_dim, padding_idx=padding_idx
        )

        self.convs = nn.ModuleList([
            nn.Conv1d(
                in_channels=embed_dim,
                out_channels=num_filters,
                kernel_size=k
            )
            for k in kernel_sizes
        ])

        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(num_filters * len(kernel_sizes), num_classes)

    def forward(self, input_ids):
        # input_ids: [B, L]
        x = self.embedding(input_ids)          # [B, L, D]
        x = x.transpose(1, 2)                  # [B, D, L]

        conv_outs = []
        for conv in self.convs:
            y = F.relu(conv(x))                # [B, C, L']
            y = F.max_pool1d(y, y.size(2))     # [B, C, 1]
            conv_outs.append(y.squeeze(2))     # [B, C]

        feat = torch.cat(conv_outs, dim=1)     # [B, C * K]
        feat = self.dropout(feat)
        logits = self.fc(feat)
        return logits
```

2. 多语言文本预处理（统一 vocab）
关键原则：
* 中文 / 日语：字符级（无需分词）
* 英文：空格分词 + lower
* 最终统一成 token 序列

```Python
# tokenizer.py
import re

def tokenize(text: str, lang: str):
    text = text.strip()
    if lang in ("zh", "ja"):
        return list(text)
    else:
        return re.findall(r"[a-zA-Z']+", text.lower())
```

3. 训练脚本（含 OOS）
```Python
# train.py
import torch
from torch.utils.data import Dataset, DataLoader
from model import TextCNN
from tokenizer import tokenize

class IntentDataset(Dataset):
    def __init__(self, samples, vocab, max_len=32):
        self.samples = samples
        self.vocab = vocab
        self.max_len = max_len

    def encode(self, tokens):
        ids = [self.vocab.get(t, self.vocab["<unk>"]) for t in tokens]
        ids = ids[:self.max_len]
        ids += [self.vocab["<pad>"]] * (self.max_len - len(ids))
        return ids

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        text, lang, label = self.samples[idx]
        tokens = tokenize(text, lang)
        return (
            torch.tensor(self.encode(tokens), dtype=torch.long),
            torch.tensor(label, dtype=torch.long),
        )

# 示例：samples = [(text, lang, label)]
# label 中需包含 OOS

model = TextCNN(
    vocab_size=len(vocab),
    embed_dim=128,
    num_classes=num_classes,
)

optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
criterion = torch.nn.CrossEntropyLoss()

loader = DataLoader(dataset, batch_size=64, shuffle=True)

for epoch in range(10):
    model.train()
    for x, y in loader:
        logits = model(x)
        loss = criterion(logits, y)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
```

4. 导出 ONNX（生产关键步骤）
```Python
# export_onnx.py
import torch
from model import TextCNN

model.eval()

dummy_input = torch.randint(0, vocab_size, (1, 32))

torch.onnx.export(
    model,
    dummy_input,
    "textcnn.onnx",
    input_names=["input_ids"],
    output_names=["logits"],
    dynamic_axes={
        "input_ids": {0: "batch"},
        "logits": {0: "batch"},
    },
    opset_version=13,
)
```
至此，你已经得到一个 多语言 Text CNN ONNX 模型。

二、Go：onnxruntime CPU 推理最小服务
1. 依赖
```bash
go get github.com/microsoft/onnxruntime-go
```

系统需安装：
onnxruntime CPU 版（x86 / ARM 均可）

2. 推理核心代码（最小可跑）
```go 
package main

import (
	"fmt"
	"log"

	ort "github.com/microsoft/onnxruntime-go"
)

func main() {
	ort.SetSharedLibraryPath("./libonnxruntime.so")
	if err := ort.InitializeEnvironment(); err != nil {
		log.Fatal(err)
	}
	defer ort.DestroyEnvironment()

	session, err := ort.NewSession("textcnn.onnx")
	if err != nil {
		log.Fatal(err)
	}
	defer session.Close()

	// 假设 max_len = 32
	input := make([]int64, 32)
	for i := range input {
		input[i] = 1
	}

	inputTensor, _ := ort.NewTensor(
		ort.NewShape(1, 32),
		input,
	)

	output, err := session.Run(
		map[string]*ort.Value{
			"input_ids": inputTensor,
		},
	)
	if err != nil {
		log.Fatal(err)
	}

	logits := output[0].Value().([][]float32)[0]
	fmt.Println("logits:", logits)
}
```

3. OOS / 拒识逻辑（工程建议）
```go 
func shouldReject(logits []float32) bool {
	top1, top2 := float32(-1e9), float32(-1e9)
	for _, v := range logits {
		if v > top1 {
			top2 = top1
			top1 = v
		} else if v > top2 {
			top2 = v
		}
	}
	if top1 < 0.6 {
		return true
	}
	if top1-top2 < 0.15 {
		return true
	}
	return false
}
```

三、与你方案的逐条对齐说明
1）Text CNN 语义泛化不足？

是的，这是已知且可控的缺点：

通过：
	* 多语言数据增强
	* 同义句模板
	* OOS 明确建模

在 ≤50 个一级意图 下是可接受的

若未来出现大量：“音量有点低了 / 声音是不是太小 / 有点听不清”
再考虑 MiniLM 替换 CNN 即可，接口不变。

2）Python + Go 架构

已完全符合：
* Python：训练 / 导出
* Go：CPU 推理 / 高并发

3）多语言支持（中 / 英 / 日）
* 不需要多模型
* 统一 vocab
* 统一 Text CNN
* 意图层共享

这是工业界非常常见的做法。

4）意图规模：10 → 50

Text CNN 在这个区间：
* 准确率稳定
* 推理成本线性增长
* OOS 仍可控

四、下一步可选增强（不做也可上线）

如果你后续需要，我可以继续提供：
* 多语言 hard negative / OOS 构造模板
* Text CNN → MiniLM 的平滑升级方案
* INT8 量化是否值得（真实收益评估）
* 日志采样 → 周期训练的数据闭环设计